words_df
words_df <- tibble(words_c, word_id, pos_attr, verified_attr) %>%
separate(word_id, into = c("article_id", "sentence_id", "word_id"))
#words_df <-
tibble(words_c, word_id, pos_attr, verified_attr) %>%
separate(word_id, into = c("article_id", "sentence_id", "word_id"))
#words_df <-
tibble(words_c, word_id, pos_attr, verified_attr) %>%
separate(word_id, into = c("article_id", "sentence_id", "word_id")) %>%
mutate(sentence_id = str_c(article_id, "-", sentence_id))
#words_df <-
tibble(words_c, word_id, pos_attr, verified_attr) %>%
mutate(article_id = word_id) %>%
separate(article_id, into = c("article_id", "sentence_id", "word")) %>%
mutate(sentence_id = str_c(article_id, "-", sentence_id)) %>%
select(-word)
#words_df <-
tibble(words_c, word_id, pos_attr, verified_attr) %>%
separate(word_id, into = c("article_id", "sentence_id", "word_id"))
words_df <-
tibble(words_c, word_id, pos_attr, verified_attr) %>%
separate(word_id, into = c("article_id", "sentence_id", "word_id"))
?lead
words_df %>%
distinct(pos_attr)
words_df %>%
count(pos_attr, sort = T)
unique(words_df$pos_attr)
words_df %>%
group_by(article_id, sentence_id) %>%
mutate(word_next = lag(words_c),
word_after = lead(words_c))
words_df %>%
group_by(article_id, sentence_id) %>%
mutate(word_next = lag(words_c),
word_after = lead(words_c),
pos_next = lag(pos_attr),
pos_after = lead(pos_attr))
words_df %>%
group_by(article_id, sentence_id) %>%
mutate(word_before = lag(words_c),
word_after = lead(words_c),
pos_before = lag(pos_attr),
pos_after = lead(pos_attr)) %>%
filter(pos_before == "PPOSAT" & pos_attr == "NN")
words_df %>%
group_by(article_id, sentence_id) %>%
mutate(word_before = lag(words_c),
word_after = lead(words_c),
pos_before = lag(pos_attr),
pos_after = lead(pos_attr)) %>%
filter(pos_before == "PPOSAT" & pos_attr == "NN") %>%
count(word_before, words_c, sort = T)
words_df %>%
group_by(article_id, sentence_id) %>%
mutate(word_before = lag(words_c),
word_after = lead(words_c),
pos_before = lag(pos_attr),
pos_after = lead(pos_attr)) #%>%
words_df %>%
group_by(article_id, sentence_id) %>%
mutate(word_before = lag(words_c),
word_after = lead(words_c),
pos_before = lag(pos_attr),
pos_after = lead(pos_attr)) %>%
tail()
add_2 <- function(x) {
x + 2
}
add_2(5)
?join
library(tidyverse)
?join
?anti_join
library(swirl)
swirl()
subjects2
coords2
subjects2 %>%
count(COSERID, number)
subjects2 %>%
count(COSERID, number) %>%
spread(number, n, fill = 0)
subjects2 %>%
count(COSERID, number) %>%
spread(number, n, fill = 0) %>%
group_by(COSERID)
swirl()
subjects2_map <- subjects2 %>%
count(COSERID, number) %>%
spread(number, n, fill = 0) %>%
group_by(COSERID) %>%
mutate(total = sum(sg, pl)) %>%
#mutate(total = sg + pl) %>%
left_join(coords2)
spain <- map_data("world", c("Spain", "Canary"))
ggplot(spain, aes(x = long, y = lat)) +
geom_map(map = spain, aes(map_id = region), fill = "white", colour = "black") +
geom_scatterpie(data = subjects2_map, aes(x = longitude, y = latitude, r = sqrt(total)/15), cols = c("sg", "pl"), alpha = 0.5) +
scale_fill_manual(breaks = c("sg", "pl"), labels = c("3sg", "3pl"), values = c("sg" = "white", "pl" = "red")) +
coord_map() +
labs(title = "Verbal agreement with singular subjects") +
theme_bw() +
theme(panel.grid = element_blank(), panel.border = element_blank(),
axis.title = element_blank(), axis.text = element_blank(), axis.ticks = element_blank(),
legend.title = element_blank(), legend.position = c(1, 0), legend.justification = c(1, 0))
library(swirlify)
library(swirl)
install.packages("swirl")
install.packages("swirl")
library(swirl)
install_course_github(
"Carlotadbm",
"Tools_for_text_analysis")
swirl()
install.packages("swirl")
library(swirl)
install_course_github(
"Carlotadbm",
"Tools_for_text_analysis")
swirl()
swirl()
?udpipe_download_model
udpipe_download_model("english-ewt")
udpipe_load_model("english-ewt-ud-2.5-191206.udpipe")
en_ewt <- udpipe_load_model("english-ewt-ud-2.5-191206.udpipe")
udpipe_download_model("english-gum")
en_ewt <- udpipe_load_model("english-gum-ud-2.5-191206.udpipe")
en_ewt <- udpipe_load_model("english-ewt-ud-2.5-191206.udpipe")
en_gum <- udpipe_load_model("english-gum-ud-2.5-191206.udpipe")
udpipe_download_model("english-lines")
en_lines <- udpipe_load_model("english-lines-ud-2.5-191206.udpipe")
udpipe_download_model("english-partut")
en_partut <- udpipe_load_model("english-partut-ud-2.5-191206.udpipe")
text
library(tidyverse)
#library(XML)
library(xml2)
file_url2 <- "https://raw.githubusercontent.com/noe-eva/NOAH-Corpus/master/blick.xml"
data2 <- read_xml(file_url2)
words <- xml_find_all(data2, "//w") #finds all w objects
words_c <- xml_text(words)
word_id <- xml_attr(words, attr = "n")
pos_attr <- xml_attr(words, attr = "pos")
verified_attr <- xml_attr(words, attr = "verified")
words_df <-
tibble(words_c, word_id, pos_attr, verified_attr) %>%
separate(word_id, into = c("article_id", "sentence_id", "word_id"))
#read file
url <- "https://raw.githubusercontent.com/noe-eva/NOAH-Corpus/master/blick.xml"
blick <- read_xml(url)
#read file
url <- "https://raw.githubusercontent.com/noe-eva/NOAH-Corpus/master/blick.xml"
blick <- read_xml(url)
url %>% read_xml()
#explore file
View(blick) #mejor
xml_structure(blick) #caótico, pero ok
blick %>% xml_structure()
#Convert into a tibble
#Articles is interesting, because it has the name of the article
articles <- xml_find_all(blick, "//article") %>% #finds all article objects
xml_attrs() %>%
enframe(name = NULL) %>%
unnest_wider(value) %>% #to transform into a tibble
rename(article_id = n)
#object s is irrelevant
xml_find_all(blick, "//s") %>%
xml_attrs %>%
enframe(name = NULL) %>%
unnest_wider(value)
#we get the attributes
words_attr <- xml_find_all(blick, "//w") %>%
xml_attrs %>%
enframe(name = NULL) %>%
unnest_wider(value) %>%
separate(n, into = c("article_id", "sentence_id", "word_id")) #we bind both words tables
#and the elements
words <- xml_find_all(blick, "//w") %>%
xml_text() %>%
enframe(name = NULL, value = "word") %>%
add_column(words_attr)
#now we join it with articles and we have all the information ready
corpus <- articles %>%
full_join(words)
##Probar Noah's
corpus
##Probar Noah's
corpus %>%
distinct(pos)
##Probar Noah's
corpus %>%
distinct(pos) %>%
print(n=70)
##Probar Noah's
corpus %>%
filter(str_detect(pos, "PTKNEG"))
##Probar Noah's
corpus %>%
filter(str_detect(pos, "PTKNEG")) %>%
distinct(word)
##Probar Noah's
corpus %>%
filter(str_detect(pos, "ART
")) %>%
distinct(word)
##Probar Noah's
corpus %>%
filter(str_detect(pos, "ART")) %>%
distinct(word)
##Probar Noah's
corpus %>%
filter(str_detect(pos, "ART")) %>%
distinct(word) %>%
print(n = Inf)
corpus %>%
filter(str_detect(word, "keis")) %>%
distinct(word) %>%
print(n = Inf)
corpus %>%
filter(str_detect(word, "keis"))
corpus %>%
filter(str_detect(word, "kei"))
##Probar Noah's
corpus %>%
filter(str_detect(pos, "PIAT")) %>%
distinct(word) %>%
print(n = Inf)
##Probar Noah's
corpus %>%
filter(str_detect(pos, "PIAT") & str_detect(word, "^[Kk]")) %>%
distinct(word) %>%
print(n = Inf)
corpus %>%
filter(str_detect(word, "kei"))
corpus %>%
group_by(article_id, sentence_id) %>%
mutate(sentence = str_c(word, collapse = " "))
corpus %>%
group_by(article_id, sentence_id) %>%
mutate(sentence = str_c(word, collapse = " ")) %>%
ungroup() %>%
filter(str_detect(pos, "PIAT") & str_detect(word, "^[Kk]"))
neg_art <- corpus %>%
group_by(article_id, sentence_id) %>%
mutate(sentence = str_c(word, collapse = " ")) %>%
ungroup() %>%
filter(str_detect(pos, "PIAT") & str_detect(word, "^[Kk]"))
View(neg_art)
?lead
?lead
library(tidyverse)
?lead
sqrt(-9)
?exp
exp(2)
(-9)^(1/2)
(-9)^(0.5)
load("/Users/carlotadebenitomoreno/switchdrive/Trabajos Ba:Ma/Master/Gabi Soares/20210124/environment.RData")
AJ_2 <- read_lines("Chat mit jüngerem Bruder_2.txt")
AJ_2 <- read_lines("Chat mit jüngerem Bruder_2.txt")
library(tidyverse)
AJ_2 <- read_lines("Chat mit jüngerem Bruder_2.txt")
AJ_2
AJ_2 %>% as_tibble()
AJ_2 %>% as_tibble() %>%
slice(-1)
AJ_2 %>% as_tibble() %>%
slice(-1) %>%
separate(value, into = c("fecha", "hora"), sep = ", ", extra = "merge")
AJ_2 %>% as_tibble() %>%
slice(-1) %>%
separate(value, into = c("fecha", "hora"), sep = ", ", extra = "merge") %>%
separate(hora, into = c("hora", "user"), sep= " - ", extra = "merge")
AJ_2 %>% as_tibble() %>%
slice(-1) %>%
separate(value, into = c("fecha", "hora"), sep = ", ", extra = "merge") %>%
separate(hora, into = c("hora", "user"), sep= " - ", extra = "merge") %>%
separate(user, into = c("user", "mensaje"), sep= ": ", extra = "merge")
AJ_2 %>% as_tibble() %>%
slice(-1) %>%
separate(value, into = c("fecha", "hora"), sep = ", ", extra = "merge") %>%
separate(hora, into = c("hora", "user"), sep= " - ", extra = "merge") %>%
separate(user, into = c("user", "mensaje"), sep= ": ", extra = "merge") %>%
mutate(ID = seq_along(fecha))
AJ_2 %>% as_tibble() %>%
slice(-1) %>%
separate(value, into = c("fecha", "hora"), sep = ", ", extra = "merge") %>%
separate(hora, into = c("hora", "user"), sep= " - ", extra = "merge") %>%
separate(user, into = c("user", "mensaje"), sep= ": ", extra = "merge") %>%
mutate(ID = seq_along(fecha))
AJ_2 %>% as_tibble() %>%
slice(-1) %>%
separate(value, into = c("fecha", "hora"), sep = ", ", extra = "merge") %>%
separate(hora, into = c("hora", "user"), sep= " - ", extra = "merge") %>%
separate(user, into = c("user", "mensaje"), sep= ": ", extra = "merge") %>%
mutate(ID = seq_along(fecha)) %>%
mutate(mensaje = tolower(mensaje))
tabla_hermanos
?set.seed
tabla_usuarios_hermanos
tabla_completa_hermanos
tabla_completa_hermanos
tabla_completa_hermanos%>%
mutate(n_palabras = count_words(mensaje))
library(tidytext)
tabla_completa_hermanos%>%
mutate(n_palabras = count_words(mensaje))
library(tokenizers)
tabla_completa_hermanos%>%
mutate(n_palabras = count_words(mensaje))
tabla_completa_hermanos
tabla_completa_hermanos%>%
mutate(n_palabras = count_words(mensaje)) %>% #CdBM: esta línea es redundante
mutate(matches_pal_esp = str_count(mensaje, palabras_esp_regex))
tabla_1_hermanos
tabla_2_hermanos
tabla_2_hermanos
tabla_2_hermanos %>%
mutate(code_switching = ifelse(lead(prop_pal) == Inf & prop_pal == 0, "switch", "no_switch"))
tabla_2_hermanos %>%
mutate(code_switching = ifelse(lead(prop_pal) == Inf & prop_pal == 0, "switch", "no_switch"))
#CdBM
tabla_2_hermanos %>%
distinct(prop_pal)
summary(tabla_2_hermanos$prop_pal)
tabla_2_hermanos %>%
filter(prop_pal < 20)
tabla_2_hermanos %>%
filter(prop_pal < 20) %>%
View()
tabla_2_hermanos %>%
filter(prop_pal < 20 & prop_pal > 1) %>%
View()
tabla_2_hermanos_porcentaje <- tabla_1_hermanos %>%
mutate(porcentaje_pal = matches_pal_esp / n_palabras *100)
tabla_2_hermanos_porcentaje
tabla_2_hermanos_porcentaje %>%
filter(tabla_2_hermanos_porcentaje > 0)
tabla_2_hermanos_porcentaje %>%
filter(!tabla_2_hermanos_porcentaje == 0) #con > no funciona, no sé por qué
tabla_2_hermanos_porcentaje %>%
filter(porcentaje_pal > 0)
tabla_2_hermanos_porcentaje <- tabla_1_hermanos %>%
select(-c(fecha, hora, matches_car_esp, matches_car_chdt))
tabla_1_hermanos %>%
select(-c(fecha, hora, matches_car_esp, matches_car_chdt)) %>%
mutate(porcentaje_pal_esp = matches_pal_esp / n_palabras *100,
porcentaje_pal_esp = matches_pal_esp / n_palabras *100)
tabla_1_hermanos %>%
select(-c(fecha, hora, matches_car_esp, matches_car_chdt)) %>%
mutate(porcentaje_pal_esp = matches_pal_esp / n_palabras *100,
porcentaje_pal_chdt = matches_pal_chdt / n_palabras *100) %>%
filter(porcentaje_pal > 0)
tabla_1_hermanos %>%
select(-c(fecha, hora, matches_car_esp, matches_car_chdt)) %>%
mutate(porcentaje_pal_esp = matches_pal_esp / n_palabras *100,
porcentaje_pal_chdt = matches_pal_chdt / n_palabras *100) %>%
filter(porcentaje_pal_esp > 0)
tabla_1_hermanos %>%
select(-c(fecha, hora, matches_car_esp, matches_car_chdt)) %>%
mutate(porcentaje_pal_esp = matches_pal_esp / n_palabras *100,
porcentaje_pal_chdt = matches_pal_chdt / n_palabras *100) %>%
filter(porcentaje_pal_esp > 0) %>%
View()
tabla_1_hermanos %>%
#select(-c(fecha, hora, matches_car_esp, matches_car_chdt)) %>%
mutate(porcentaje_pal_esp = matches_pal_esp / n_palabras *100,
porcentaje_pal_chdt = matches_pal_chdt / n_palabras *100) %>%
filter(porcentaje_pal_esp > 0) %>%
View()
tabla_1_hermanos %>%
select(-c(fecha, hora, matches_car_esp, matches_car_chdt)) %>%
mutate(porcentaje_pal_esp = matches_pal_esp / n_palabras *100,
porcentaje_pal_chdt = matches_pal_chdt / n_palabras *100) %>%
filter(porcentaje_pal_esp > 0 & porcentaje_pal_esp > porcentaje_pal_chdt) %>%
View()
tabla_1_hermanos %>%
select(-c(fecha, hora, matches_car_esp, matches_car_chdt)) %>%
mutate(porcentaje_pal_esp = matches_pal_esp / n_palabras *100,
porcentaje_pal_chdt = matches_pal_chdt / n_palabras *100) %>%
filter(!(porcentaje_pal_esp > 0 & porcentaje_pal_esp > porcentaje_pal_chdt)) %>%
View()
tabla_1_hermanos %>%
select(-c(fecha, hora, matches_car_esp, matches_car_chdt)) %>%
mutate(porcentaje_pal_esp = matches_pal_esp / n_palabras *100,
porcentaje_pal_chdt = matches_pal_chdt / n_palabras *100) %>%
filter(!mesaje == "<medien ausgeschlossen>") %>%
#mutate(lengua = ifelse(porcentaje_pal_esp > 0 & porcentaje_pal_esp > porcentaje_pal_chdt, "esp", "chdt"))
#filter(!(porcentaje_pal_esp > 0 & porcentaje_pal_esp > porcentaje_pal_chdt)) %>% #básicamente todo chdt
filter(porcentaje_pal_esp > 0 & porcentaje_pal_esp > porcentaje_pal_chdt) %>% #básicamente todo esp
View()
tabla_1_hermanos %>%
select(-c(fecha, hora, matches_car_esp, matches_car_chdt)) %>%
mutate(porcentaje_pal_esp = matches_pal_esp / n_palabras *100,
porcentaje_pal_chdt = matches_pal_chdt / n_palabras *100) %>%
filter(!mensaje == "<medien ausgeschlossen>") %>%
#mutate(lengua = ifelse(porcentaje_pal_esp > 0 & porcentaje_pal_esp > porcentaje_pal_chdt, "esp", "chdt"))
#filter(!(porcentaje_pal_esp > 0 & porcentaje_pal_esp > porcentaje_pal_chdt)) %>% #básicamente todo chdt
filter(porcentaje_pal_esp > 0 & porcentaje_pal_esp > porcentaje_pal_chdt) %>% #básicamente todo esp
View()
tabla_1_hermanos %>%
select(-c(fecha, hora, matches_car_esp, matches_car_chdt)) %>%
mutate(porcentaje_pal_esp = matches_pal_esp / n_palabras *100,
porcentaje_pal_chdt = matches_pal_chdt / n_palabras *100) %>%
filter(!mensaje == "<medien ausgeschlossen>") %>%
#mutate(lengua = ifelse(porcentaje_pal_esp > 0 & porcentaje_pal_esp > porcentaje_pal_chdt, "esp", "chdt"))
filter(!(porcentaje_pal_esp > 0 & porcentaje_pal_esp > porcentaje_pal_chdt)) %>% #básicamente todo chdt
#filter(porcentaje_pal_esp > 0 & porcentaje_pal_esp > porcentaje_pal_chdt) %>% #básicamente todo esp
View()
tabla_1_hermanos %>%
select(-c(fecha, hora, matches_car_esp, matches_car_chdt)) %>%
mutate(porcentaje_pal_esp = matches_pal_esp / n_palabras *100,
porcentaje_pal_chdt = matches_pal_chdt / n_palabras *100) %>%
filter(!mensaje == "<medien ausgeschlossen>") %>%
mutate(lengua = ifelse(porcentaje_pal_esp > 0 & porcentaje_pal_esp > porcentaje_pal_chdt, "esp", "chdt")) %>%
#filter(!(porcentaje_pal_esp > 0 & porcentaje_pal_esp > porcentaje_pal_chdt)) %>% #básicamente todo chdt
#filter(porcentaje_pal_esp > 0 & porcentaje_pal_esp > porcentaje_pal_chdt) %>% #básicamente todo esp
View()
tabla_1_hermanos %>%
select(-c(fecha, hora, matches_car_esp, matches_car_chdt)) %>%
mutate(porcentaje_pal_esp = matches_pal_esp / n_palabras *100,
porcentaje_pal_chdt = matches_pal_chdt / n_palabras *100) %>%
filter(!mensaje == "<medien ausgeschlossen>") %>%
mutate(lengua = ifelse(porcentaje_pal_esp > 0 & porcentaje_pal_esp > porcentaje_pal_chdt, "esp", "chdt"),
code_switching = ifelse(lead(lengua) != lengua, "switch", "no_switch")) %>%
#filter(!(porcentaje_pal_esp > 0 & porcentaje_pal_esp > porcentaje_pal_chdt)) %>% #básicamente todo chdt
#filter(porcentaje_pal_esp > 0 & porcentaje_pal_esp > porcentaje_pal_chdt) %>% #básicamente todo esp
View()
tabla_1_hermanos %>%
select(-c(fecha, hora, matches_car_esp, matches_car_chdt)) %>%
mutate(porcentaje_pal_esp = matches_pal_esp / n_palabras *100,
porcentaje_pal_chdt = matches_pal_chdt / n_palabras *100) %>%
filter(!mensaje == "<medien ausgeschlossen>") %>%
mutate(lengua = ifelse(porcentaje_pal_esp > 0 & porcentaje_pal_esp > porcentaje_pal_chdt, "esp", "chdt"),
code_switching = ifelse(lag(lengua) != lengua, "switch", "no_switch")) %>%
#filter(!(porcentaje_pal_esp > 0 & porcentaje_pal_esp > porcentaje_pal_chdt)) %>% #básicamente todo chdt
#filter(porcentaje_pal_esp > 0 & porcentaje_pal_esp > porcentaje_pal_chdt) %>% #básicamente todo esp
View()
tabla_1_hermanos
tabla_1_hermanos %>%
select(-c(fecha, hora, matches_car_esp, matches_car_chdt)) %>%
mutate(porcentaje_pal_esp = matches_pal_esp / n_palabras *100,
porcentaje_pal_chdt = matches_pal_chdt / n_palabras *100)
tabla_1_hermanos %>%
select(-c(fecha, hora, matches_car_esp, matches_car_chdt)) %>%
mutate(porcentaje_pal_esp = matches_pal_esp / n_palabras *100,
porcentaje_pal_chdt = matches_pal_chdt / n_palabras *100) %>%
filter(!(porcentaje_pal_esp > 0 & porcentaje_pal_esp > porcentaje_pal_chdt)) %>% #básicamente todo chdt
#filter(porcentaje_pal_esp > 0 & porcentaje_pal_esp > porcentaje_pal_chdt) %>% #básicamente todo esp
View()
tabla_1_hermanos %>%
select(-c(fecha, hora, matches_car_esp, matches_car_chdt)) %>%
mutate(porcentaje_pal_esp = matches_pal_esp / n_palabras *100,
porcentaje_pal_chdt = matches_pal_chdt / n_palabras *100) %>%
#filter(!(porcentaje_pal_esp > 0 & porcentaje_pal_esp > porcentaje_pal_chdt)) %>% #básicamente todo chdt
filter(porcentaje_pal_esp > 0 & porcentaje_pal_esp > porcentaje_pal_chdt) %>% #básicamente todo esp
View()
tabla_1_hermanos %>%
select(-c(fecha, hora, matches_car_esp, matches_car_chdt)) %>%
mutate(porcentaje_pal_esp = matches_pal_esp / n_palabras *100,
porcentaje_pal_chdt = matches_pal_chdt / n_palabras *100) %>%
filter(!mensaje == "<medien ausgeschlossen>") %>%
mutate(lengua = ifelse(porcentaje_pal_esp > 0 & porcentaje_pal_esp > porcentaje_pal_chdt, "esp", "chdt"),
code_switching = ifelse(lag(lengua) != lengua, "switch", "no_switch")) %>%
View()
tabla_1_hermanos %>%
select(-c(fecha, hora, matches_car_esp, matches_car_chdt)) %>%
mutate(porcentaje_pal_esp = matches_pal_esp / n_palabras *100,
porcentaje_pal_chdt = matches_pal_chdt / n_palabras *100) %>%
filter(porcentaje_pal_esp > 0 & porcentaje_pal_chdt > 0)
tabla_1_hermanos %>%
select(-c(fecha, hora, matches_car_esp, matches_car_chdt)) %>%
mutate(porcentaje_pal_esp = matches_pal_esp / n_palabras *100,
porcentaje_pal_chdt = matches_pal_chdt / n_palabras *100) %>%
filter(porcentaje_pal_esp > 0 & porcentaje_pal_chdt > 0) %>%
View
tabla_1_hermanos
library(swirl)
swirl()
?InstallCourses
swirl()
library(swirl)
swirl()
skip()
skip()
library(swirl)
swirl()
library(tidyverse)
skip()
#Librerías
library(tidyverse)
library(swirlify)
setwd("~/switchdrive/Catching_online_language")
new_lesson("Reading WhatsApp chats", "Catching online language")
test_lesson()
demo_lesson()
add_to_manifest()
demo_lesson()
demo_lesson()
wa
demo_lesson()
wa
wa %>% as_tibble()
demo_lesson()
wa
wa %>% as_tibble()
demo_lesson()
wa
demo_lesson()
wa
wa %>% as_tibble()
